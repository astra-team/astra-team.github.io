import re
import urllib.parse
import urllib.request
import os

strut_id = ["1124151","246190","454685"]
url = 'https://api.archives-ouvertes.fr/search/?q=structId_i:('+"%20OR%20".join(strut_id)+')&wt=bibtex&start=0&rows=5000'
#&fq=submittedDateY_i:[2022%20TO%20*]'
print(url)

path = 'rits-astra'
path_tmp = path + "_hal.bib"
urllib.request.urlretrieve(url, path_tmp)

print("Written in: " + path_tmp)

print("*** Clean up bibtex")
surrounding_chars_to_remove = ".-_!?"

fp = open(path_tmp, "r")
lines = fp.read().split("\n")
fp.close()

print("Keywords: convert ';' separators to ',' AND clean up special chars "+surrounding_chars_to_remove)
for i,l in enumerate(lines):
  g = re.search("^([ \t]*keywords[ \t]*=[ \t]*\\{)(.*)(\\},)$", l, flags=re.IGNORECASE)
  if g is None:
    continue

  keywords = [k.strip().strip(surrounding_chars_to_remove).replace(",", "") for k in g[2].split(";")]

  l_new = g[1] + " , ".join(keywords) + g[3]
  # print("Replace line %d/%d:" % (i, len(lines)))
  # print(l)
  # print("with:")
  # print(l_new)
  lines[i] = l_new

print("Clean PDF url to point to generic hal PDF url, instead of custom URI (to avoid non-ascii character issues)")
for i,l in enumerate(lines):
  g = re.search("^([ \t]*PDF[ \t]*=[ \t]*\\{https://.*\\.?hal\\.science/.*)/file/(.*).pdf(\\},)$", l, flags=re.IGNORECASE)
  if g is None:
    continue

  l_new = g[1] + "/document" + g[3]
  lines[i] = l_new

print("Write clean file in: " + path)
fp = open(path+".bib", "w")
fp.write("% DO NOT EDIT THE FILE MANUALLY"+"\n")
fp.write("% This file is automatically generated by scripts/publication-update.sh"+"\n")
fp.write("% Any changes might be overwritten anytime"+"\n")
fp.write("\n")
fp.write("\n")
for l in lines:
  fp.write(l+"\n")
fp.close()

print("Done")
